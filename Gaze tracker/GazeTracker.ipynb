{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "175079ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import pyautogui as pag\n",
    "\n",
    "%run Config.ipynb\n",
    "%run Utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65652998",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, frame=cap.read()\n",
    "    gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    rects=detector(gray, 1) # detects the presence of face in the given frame\n",
    "    \n",
    "    for (i, rect) in enumerate(rects):\n",
    "        \n",
    "        shape=predictor(gray, rect) #predicts the facial landmarks in the detected face\n",
    "                \n",
    "        shape=npshape(shape) #converts the shape into a numpy array of 68x2 where each row corresponds \n",
    "                             #to the coordinates of the landmarks in the image\n",
    "            \n",
    "#         for (x, y) in shape:\n",
    "#             cv2.circle(frame, (x,y), 2, (255,0,0), -1)\n",
    "    \n",
    "        mask=np.zeros(frame.shape[:2], dtype=np.uint8) #declares an matrix of same size as frame\n",
    "        \n",
    "        mask=mask_of_eye(mask, left, shape) #fills the area covered by the eyes with white using fillConvexPoly method\n",
    "        mask=mask_of_eye(mask, right, shape)\n",
    "        \n",
    "        mask=cv2.dilate(mask, kernel, 5) #a kernel of 9x9 is used to convolve over the image\n",
    "        \n",
    "        eyes=cv2.bitwise_and(frame, frame, mask=mask) #bitiwise and operation makes the entire frame black \n",
    "                                                      #except where the eyes are coloured. \n",
    "        \n",
    "        #makes the background white\n",
    "        mask=(eyes==[0,0,0]).all(axis=2)\n",
    "        eyes[mask]=[255,255,255]\n",
    "        \n",
    "        gray_eyes=cv2.cvtColor(eyes, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        \n",
    "        #thresholding of frame is done for contouring\n",
    "        _,thresh=cv2.threshold(gray_eyes, 100, 255, cv2.THRESH_BINARY)\n",
    "        thresh = cv2.erode(thresh, None, iterations=2)\n",
    "        thresh = cv2.dilate(thresh, None, iterations=4)\n",
    "        thresh = cv2.medianBlur(thresh, 3)\n",
    "        \n",
    "        mid = (shape[42][0] + shape[39][0]) // 2\n",
    "        \n",
    "        thresh = cv2.bitwise_not(thresh) #Cotouring requires that the object being \n",
    "                                         #detected should be white with a black background.\n",
    "        \n",
    "        #contours are calculated for left and right eyes. Moments are used to calculate centroid of the eyes.\n",
    "        cx1, cy1=contouring(thresh[:, 0:mid], mid, frame)\n",
    "        cx2, cy2=contouring(thresh[:, mid:], mid, frame, True)\n",
    "        \n",
    "\n",
    "        #The ratio of width and height of the eyes with that of screen resolution is calculated. \n",
    "        #The facial landmarks used for this are 40, 37, 39, 41\n",
    "        \n",
    "        ratio_x=2000/abs(shape[39][0]-shape[36][0]) \n",
    "        ratio_y=800/abs(shape[38][1]-shape[40][1])\n",
    "        \n",
    "        if prev1==None and prev2==None:\n",
    "            if cx1==None or cx2==None:\n",
    "                prev1=(0,0)\n",
    "                prev2=(0,0)\n",
    "            else:\n",
    "                prev1=(cx1, cy1)\n",
    "                prev2=(cx2, cy2)\n",
    "            \n",
    "        if cx1==None or cy1==None:\n",
    "            cx1, cy1=prev1\n",
    "            \n",
    "        if cx2==None or cy2==None:\n",
    "            cx2, cy2=prev2\n",
    "        \n",
    "        #Difference between the previous and current position of the eyes is used \n",
    "        #to calculate the shift in position of cursor\n",
    "        \n",
    "        horz=(prev1[0]-cx1+prev2[0]-cx2)//2\n",
    "        vert=(cy1-prev1[1]+cy2-prev2[1])//2\n",
    "        \n",
    "        pag.moveRel(horz*ratio_x,vert*ratio_y) #move horizontally and vertically\n",
    "            \n",
    "            \n",
    "        prev1=(cx1, cy1)\n",
    "        prev2=(cx2, cy2)\n",
    "\n",
    "        frame=cv2.flip(frame, 1)\n",
    "        cv2.imshow('res', frame)        \n",
    "        \n",
    "    if cv2.waitKey(1) & 0xff==ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4d333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e7fe08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbee4607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
